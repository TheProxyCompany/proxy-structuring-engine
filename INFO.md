# Proxy Structuring Engine (PSE) Overview

Imagine having a personal assistant that not only listens to your requests but also organizes everything perfectly, ensuring that every task is completed in the most efficient and structured way possible. Thatâ€™s what the structuring engine does for advanced AI models.

### Example:

Without PSE:
```
User: "Give me a summary of this article."
Model: "The article talks about climate change, its effects, and possible solutions."
```

With PSE:
```
User: "Give me a summary of this article."
Model: {
  "title": "Climate Change Overview",
  "summary": "The article discusses climate change, its effects, and possible solutions."
}
```

Notice how the second response is neatly structured and ready for further use, like feeding it into another system or displaying it in a user-friendly format.

## How Does It Work?

### The Armor Metaphor ğŸ›¡ï¸

PSE acts like a **suit of armor** for language models.

- **Protection and Enhancement**: Just as armor protects a knight without changing who they are, PSE shields language models from producing messy or unstructured outputs.
- **Guided Actions**: Armor directs a knightâ€™s movements. Similarly, PSE guides the language model to follow specific formats and structures.
- **Universal Fit**: Armor can be worn by any knight. PSE is versatile and works with various language models, enhancing their capabilities seamlessly.

### The Explorer Probes

PSE uses "walkers" that operate like **explorer probes**.

- **Self-Replication**: These walkers duplicate themselves to explore multiple paths, ensuring every possible correct response is considered.
- **Parallel Exploration**: By exploring different directions at the same time, PSE finds the best and most accurate outputs quickly.
- **Efficiency**: This method avoids backtracking, making the entire process faster and more reliable.

#### Enhanced ASCII Diagram of Walkers:

```
                Start ğŸ¬
                  |
          +-------+-------+
          |       |       |
        Path   Path   Path
          A       B       C
         / \             / \
       D     E         F     G
```

*Walkers explore multiple paths in parallel, discarding invalid ones.*

## Core Components

### State Machine âš™ï¸

Imagine a **roadmap** where each intersection represents a part of the conversation. The State Machine ensures that the language model follows the best route to deliver structured and meaningful responses.

#### State Machine Diagram:

```
           +-----------+
           |   Start   |
           +-----+-----+
                 |
           +-----v-----+
           |  State 1  |
           +-----+-----+
                 |
          +------+------+
          |             |
     +----v----+   +----v----+
     | State 2 |   | State 3 |
     +----+----+   +----+----+
          |             |
          +------+------+
                 |
           +-----v-----+
           |    End    |
           +-----------+
```

*The State Machine guides the model through predefined states.*

### Walker ğŸš¶

Walkers are like little **explorers** navigating the roadmap. They move through different states, ensuring every response fits perfectly within the defined structure.

- **Example**: If the model is generating a JSON response, the walker ensures that each key-value pair is correctly placed and formatted.

#### Walker's Journey:

```
[Start] --"name"--> [State 1] --"age"--> [State 2] --"location"--> [End]
```

*The walker progresses through states, filling in required fields.*

### Driver ğŸ¯

The Driver is the **conductor**, coordinating how walkers interact with the language model. It ensures that only valid responses are generated, guiding the walkers along the correct paths.

- **Example**: The Driver might instruct, "Expect a string here," ensuring the model generates appropriate data.

### Token Acceptor ğŸ›‚

Think of Token Acceptors as **gatekeepers**. They decide which pieces of the response are allowed at each point, keeping everything on track.

- **Example**: In a list generation, the Token Acceptor ensures only valid items are added.

#### System Overview:

```
[Language Model ğŸ¤–]
        |
        v
[   Driver ğŸ¯   ]
        |
        v
[State Machine âš™ï¸] <---> [Walker ğŸš¶]
        |
        v
[Token Acceptor ğŸ›‚]
```

*The components work together to produce structured outputs.*

## How PSE Transforms Language Models

With PSE in place, language models become **action-oriented assistants**:

- **Structured Responses**: Outputs are neatly organized, reducing errors and making them ready for immediate use.
- **Reliable Execution**: Responses follow predefined formats, ensuring consistency across different interactions.
- **Seamless Integration**: PSE works behind the scenes, enhancing the model without requiring any changes to its core functionality.

### Example:

Without PSE:
```
User: "Generate a JSON object for a user profile."
Model: "Name: John, Age: 30, Location: New York"
```

With PSE:
```
User: "Generate a JSON object for a user profile."
Model: {
  "name": "John",
  "age": 30,
  "location": "New York"
}
```

In the second example, the output is structured and ready to be used in any system that requires a JSON format.

---
